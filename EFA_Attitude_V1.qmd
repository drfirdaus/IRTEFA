---
title: "EFA_Attitude_V1"
author: "firdaus"
format: 
  html:
    theme: cosmo
    toc: true
    toc-location: left
    number-sections: true
    self-contained: true
editor: visual
---

# Preliminaries

## Load libraries

```{r}
library(foreign)  # for importing SPSS data
library(psych)  # for psychometrics
library(lattice)  # easy to plot multivariate plots
library(readxl)
library(dplyr)
```

## Load dataset

```{r}
data1= read_xlsx("EFA_Attitude_V1.xlsx")
```

```{r}
names(data1)
```

```{r}
head(data1)
```

## Coding the answers

```{r}
# Define mapping functions
likert_map <- function(x) {
  recode <- c(
    "Sangat tidak setuju" = 1,
    "Tidak setuju"        = 2,
    "Tidak pasti"         = 3,
    "Setuju"              = 4,
    "Sangat setuju"       = 5
  )
  recode[match(tolower(x), tolower(names(recode)))]
}

likert_reverse <- function(x) {
  recode <- c(
    "Sangat tidak setuju" = 5,
    "Tidak setuju"        = 4,
    "Tidak pasti"         = 3,
    "Setuju"              = 2,
    "Sangat setuju"       = 1
  )
  recode[match(tolower(x), tolower(names(recode)))]
}

# List of reverse-coded items
reverse_items <- c("A7","A8","A9","A10","A11","A12","A13",
                   "A20","A21","A23","A25","A27","A29")

# Apply transformation from data1 -> data2
data2 <- data1

for (col in names(data2)) {
  if (col %in% reverse_items) {
    data2[[col]] <- likert_reverse(data2[[col]])
  } else {
    data2[[col]] <- likert_map(data2[[col]])
  }
}

# Convert all to numeric
data2 <- as.data.frame(lapply(data2, as.numeric))

```

```{r}
head(data2)
```

```{r}
str(data2)
```

# Exploratory factor analysis

## Descriptive statistics

```{r}
describe(data2)
```

## % of response to options per item

```{r}
response.frequencies(data2)
```

## Normality of data

### Univariate normality

#### Histogram

```{r}
cat(names(data2), sep = " + ")
```

```{r}
histogram(~ A1 + A2 + A3 + A4 + A5 + A6 + A7 + A8 + A9 + A10 + A11 + A12 + A13 + A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22 + A23 + A24 + A25 + A26 + A27 + A28 + A29 + A30,
          data = data2)
```

#### Shapiro Wilk's test

```{r}
mapply(shapiro.test, data2)
```

#### Multivariate normality

To say the data are multivariate normal:

-   *z*-kurtosis \< 5 ([Bentler, 2006](https://wnarifin.github.io/lecture/mstat/efa_medstat_practical.html#ref-bentler2006)) and the *P*-value should be ≥ 0.05

-   The plot should also form a straight line ([Arifin, 2015](https://wnarifin.github.io/lecture/mstat/efa_medstat_practical.html#ref-arifin2015))

Run Mardia’s multivariate normality test,

```{r}
mardia(data2)
```

## Step 1

### Check suitability of data for analysis

#### Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy (MSA)

```{r}
KMO(data2)
```

#### Bartlet's test of sphericity

```{r}
cortest.bartlett(data2)
```

### Determine the number of factors

#### Eigen value & scree plot

```{r}
scree = scree(data2)
print(scree)
```

#### Parallel analysis

```{r}
parallel = fa.parallel(data2, fm = "pa", fa = "fa")
```

#### Very simple structure (VSS) criterion & Velicer's minimum average partial (MAP) criterion)

```{r}
vss(data2)
```

## Step 2

### Run EFA 4 factors

Cut off factor loading based on Hair (2019) ( 200 sample -\> factor loading 0.4)

```{r}
fa = fa(data2, nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa, cut = .4, digits = 3)  # cut = .3 to view only FLs > 0.3
```

**Poor items identified**

A20 (low communality)

A23 (poor FL and communality)

A24 (low communality)

No factor with cross-loading

Factor correlation is all \<0.85

```         
 With factor correlations of        PA1   PA3   PA4   PA2 PA1 1.000 0.589 0.308 0.144
```

## Step 3

### Item A20 Removal

```{r}
fa1 = fa(subset(data2, select = -A20), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa1, cut = .4, digits = 3)
```

Poor FL : A21, A23, A24

Poor communality : A21, A23, A24, A25

#### Remove A20 & A21

```{r}
fa2 = fa(subset(data2, select = -c(A20, A21)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa2, cut = .4, digits = 3)
```

Poor FL : A23, A24, A25, A26, A27, A29

Poor communality : A23, A24

#### Remove A20, A21, A23

```{r}
fa3 = fa(subset(data2, select = -c(A20, A21, A23)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa3, cut = .4, digits = 3)

```

Poor FL : A24, A25, A26, A27, A29

Poor Comm : A24, A25

#### Remove A20, A21, A23, A24

```{r}
fa4 = fa(subset(data2, select = -c(A20, A21, A23,A24)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa4, cut = .4, digits = 3)
```

#### Remove A20, A21, A23, A24, A25

```{r}
fa5 = fa(subset(data2, select = -c(A20, A21, A23, A24, A25)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa5, cut = .4, digits = 3)
```

#### Remove A20, A21, A23, A24, A25, A26

```{r}
fa6 = fa(subset(data2, select = -c(A20, A21, A23, A24, A25, A26)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa6, cut = .4, digits = 3)
```

#### Remove A20, A21, A23, A24, A25, A26, A27

```{r}
fa7 = fa(subset(data2, select = -c(A20, A21, A23, A24, A25, A26, A27)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa7, cut = .4, digits = 3)
```

#### Remove A20, A21, A23, A24, A25, A26, A27, A29

```{r}
fa8 = fa(subset(data2, select = -c(A20, A21, A23, A24, A25, A26, A27, A29)), nfactors = 4, fm = "pa", rotate = "oblimin")
print(fa8, cut = .4, digits = 3)
```

## Summary

**PA1** : A14, A15, A16, A17, A18, A19, A22, A28, A30

**PA2** : A7, A8, A9

**PA3** : A1, A2, A3, A4, A5, A6

**PA4** : A10, A11, A12, A13

# Internal Consistency Reliability

## Cronbach's Alpha

```{r}
PA1 = c("A14","A15","A16","A16","A17","A18","A19", "A22", "A28","A30")
PA2 = c("A7","A8","A9")
PA4 = c("A10","A11","A12","A13")
PA3 = c("A1","A2","A3","A4","A5","A6")
```

### PA1

```{r}
alpha.pa1 = alpha(data2[PA1])
print(alpha.pa1, digits = 3)
```

### PA2

```{r}
alpha.pa2 = alpha(data2[PA2])
print(alpha.pa2, digits = 3)
```

### PA3

```{r}
alpha.pa3 = alpha(data2[PA3])
print(alpha.pa3, digits = 3)
```

### PA4

```{r}
alpha.pa4 = alpha(data2[PA4])
print(alpha.pa4, digits = 3)
```
