---
title: "IRT"
author: "firdaus"
format: docx
editor: visual
---

# Prepare Environment

## Load Libraries

```{r}
library(psych)        # For basic psychometrics and scale reliability analysis
library(foreign)      # For reading and writing data in foreign statistical formats
library(ltm)          # To fit 2PL IRT models and other latent trait models
library(irtoys)       # For IRT utilities
library(mirt)         # Modern IRT package for multi-item response theory
library(latticeExtra) # For enhanced plotting in lattice-based plots
library(tidyverse)    # For data manipulation, cleaning, and visualization
library(haven)        # For importing and exporting SPSS, Stata, and SAS files
library(writexl)      # For exporting data frames to Excel files
library(readxl)       # For reading data from Excel files
```

## Load Data

```{r}
data1=read_xlsx("IRT_knowledge_V1.xlsx") ##read data from Excel 
names(data1) # List down variables in the data set
dim(data1)  # Data set consists of 37 variables and 177 parents
```

### Recode Data

```{r}
# Define reverse-coded items
reverse_items <- c("K2", "K3", "K4", "K5", "K8", "K10", "K35")

# Recode
data2 <- data1 %>%
  mutate(across(
    -all_of(reverse_items), 
    ~ case_when(
      tolower(.) == "ya" ~ 1,
      tolower(.) == "tidak" ~ 0,
      tolower(.) == "tidak pasti" ~ 2,
      TRUE ~ NA_real_
    )
  )) %>%
  mutate(across(
    all_of(reverse_items),
     ~ case_when(
      tolower(.) == "ya" ~ 0,
      tolower(.) == "tidak" ~ 1,
      tolower(.) == "tidak pasti" ~ 2,
      TRUE ~ NA_real_
    )
  ))
```

```{r}
#Recode 1 = 1 (correct answer), 2 and 0 = 0 (incorrect answer)

data3 <- data2 %>%
  mutate(across(
    everything(),
    ~ case_when(
      . == 1 ~ 1,
      . %in% c(0, 2) ~ 0,
      TRUE ~ NA_real_
    )
  ))
```

# Descriptive Statistics

## Response Frequencies

```{r}
response.frequencies(data3)
```

### Descriptive Statistics

```{r}
descript(data3)
```

# Fitting 2PL IRT Model with `ltm` Package

## Fit 2PL Model (ltm)

```{r}
irt.data3 <- ltm(data3 ~ z1, IRT.param = TRUE)
```

## Item Parameter Estimates

```{r}
# Obtain difficulty and discrimination parameter estimates
item_parms <- coef(irt.data3)
```

```{r}
# Tidy view: Item | a (Discrimination) | b (Difficulty)

item_parms_tbl <- item_parms |>
  as.data.frame() |>
  transform(Item = rownames(item_parms),
            Difficulty = Dffclt,
            Discrimination = Dscrmn) |>
  (\(d) d[, c("Item", "Difficulty", "Discrimination")])() |>
  (\(d) within(d, { 
    Difficulty <- round(Difficulty, 3)
    Discrimination <- round(Discrimination, 3)
  }))()

item_parms_tbl
```

## Model Summary

```{r}
# Includes log-likelihood, AIC/BIC, SEs, and Wald z-values
summary(irt.data3)
```

## Items Removal Plan 1

**Selection criteria a \> 0.64 (moderate discrimination) (Baker, 2001) ; -3 \< b \> +3**

K2 - a = 0.47

K3 - a = 0.39

K5 - a = 0.08 , b = -9.3762

K7 - a = 0.26

K8 - a = 0.20

K9 - a = 0.33

K10 - a = 0.30

K11 - a = 0.35

K24 - a = 16.9641 (?Overfitting)

K35 - a = 0.31

### 2PL Model - Remove Items

```{r}
# Remove the items
irt_removed_items <- c("K2", "K3", "K5", "K7", "K8", "K9", "K10", "K11","K35","K24")

# Create new dataset with only included items
data4 <- data3 %>% dplyr::select(-any_of(irt_removed_items))
```

### Descriptive Statistics

```{r}
descript(data4)
```

### Refit 2PL Model

```{r}
irt.data4 <- ltm(data4 ~ z1, IRT.param = TRUE)
```

### Item Parameter Estimates

```{r}
# Obtain difficulty and discrimination parameter estimates
item_parms_refined <- coef(irt.data4)

# Tidy view: Item | a (Discrimination) | b (Difficulty)

item_parms_refined_tbl <- item_parms_refined |>
  as.data.frame() |>
  transform(Item = rownames(item_parms_refined),
            Difficulty = Dffclt,
            Discrimination = Dscrmn) |>
  (\(d) d[, c("Item", "Difficulty", "Discrimination")])() |>
  (\(d) within(d, { 
    Difficulty <- round(Difficulty, 3)
    Discrimination <- round(Discrimination, 3)
  }))()

item_parms_refined_tbl
```

### Model Summary

```{r}
# Includes log-likelihood, AIC/BIC, SEs, and Wald z-values
summary(irt.data4)
```

## Graphical Presentation

### Item Characteristic Curves (ICC)

```{r}
# ICC for All Items
# Plot ICC for all items
plot(irt.data4, type = "ICC", legend = TRUE)
```

```{r}
# ICC for Individual Items

# Get total number of items
ICC_items <- nrow(coef(irt.data4))

# Plot ICC for each item
for (i in 1:ICC_items) {
  plot(irt.data4, type = "ICC", legend = TRUE, items = i)
}
```

## Goodness-of-Fit Tests

### Item Fit Statistics

```{r}
item_fit <- item.fit(irt.data4)
item_fit
```

### Fit on the Two-Way Margins

```{r}
margins_output <- margins(irt.data4)
margins_output
```

### Person Fit Statistics

```{r}
person_fit <- person.fit(irt.data4)
person_fit
```

# Checking Assumptions

## Unidimensionality

```{r}
set.seed(2025)
unidimTest(irt.data4) #Take A long time, insert # if want to skip and avoid long time
```

### Checking Dominant Factor (Essential Unidimensionality)

```{r}
# Extract the response data from the fitted model
irt_mat <- as.matrix(irt.data4$X)

# Parallel analysis
library(psych)
fa.parallel(irt_mat, fa="fa")

# Eigenvalues
ev <- eigen(cor(irt_mat, use = "pairwise.complete.obs"))$values

# First and second eigenvalues
first_ev <- ev[1]
second_ev <- ev[2]

# Ratio
dominance_ratio <- first_ev / second_ev

# Print
first_ev
second_ev
dominance_ratio

```

Parallel analysis suggested up to seven factors, as seven eigenvalues from the actual data exceeded those from randomly simulated data. However, the scree plot demonstrated a sharp drop between the first (9.02) and second (2.51) eigenvalues, yielding a ratio of 3.59. This indicates a single dominant factor underlying item responses, with additional weaker factors. Consistent with the concept of **essential unidimensionality** (Reckase, 1979; Hambleton, Swaminathan, & Rogers, 1991; Embretson & Reise, 2000), the scale was considered suitable for unidimensional IRT modeling despite the presence of minor secondary dimensions.

```{r}
class(irt.data4)
str(irt.data4, max.level = 1)

```

## Local Independence

### Yen’s Q3 residual cYen’s Q3 residual correlationsorrelations

```{r}
# ==========================================
# Load required package
# ==========================================
library(mirt)
library(mokken)

# Extract the raw item response matrix from the ltm object
irt_mat <- as.data.frame(irt.data4$X)   # now it's a dataframe
irt_mat <- as.matrix(irt_mat)           # convert to numeric matrix



# ==========================================
# 1. Fit a unidimensional 2PL model
# ==========================================

mod2pl <- mirt(irt_mat, 1, itemtype = "2PL")
mod1pl <- mirt(irt_mat, 1, itemtype = "Rasch")

# ==========================================
# 2. Assumption: Local Independence
# ==========================================
# (a) Yen’s Q3 residual correlations
# Q3_resid <- resid(mod2pl, type = "Q3")
# Assumption 2: Local Independence
Q3_resid <- residuals(mod2pl, type = "Q3")

Q3_resid   # inspect residual correlations (Q3 > .20 may indicate local dependence)

# Chen & Thissen’s LD χ² statistic
LD_resid <- residuals(mod2pl, type = "LD")
LD_resid  # values > 10 indicate local dependence
```

Priority clusters to address (strongest first):

**K15–K16** (Q3 = 0.800; LD = 70.6) → almost certainly redundant; keep one.

**K26–K27–K28–K29** (multiple LD \> 14; Q3 up to 0.556) → reduce to 1–2 items or reword to separate cues.

**K32–K33 (and K31)** (LD 25.4; Q3 0.581, 0.254) → likely very similar content; trim or rephrase.

**K34–K36–K37** (LD ≈ 12–13; Q3 ≈ 0.35–0.39) → consider trimming one.

**K23–K25** (LD 20.6; Q3 0.697) → choose one or reword to target different facets (e.g., medical consequence vs psychological).

**K4–K6** (LD 16.3; Q3 0.295) → consider keeping one or differentiating wording.

## Monotonicity

```{r}
# ==========================================
# 3. Assumption: Monotonicity
# ==========================================

# (a) Plot Item Characteristic Curves (ICCs) to visually check monotonicity
plot(mod2pl, type = "trace")   # S-shaped, increasing curves are expected

# (b) Optional: Use Mokken scale analysis for monotonicity check

# Run monotonicity check
check.monotonicity(irt_mat)  # flags items with non-monotonic patterns
```

## Model Fitness

### Global fit statistics

```{r}
# ==========================================
# 4. Assumption: Model Fit
# ==========================================
# (a) Global fit statistics (M2, RMSEA, SRMSR)
M2(mod2pl)   # RMSEA < 0.08 and SRMSR < 0.05 = good fit
```

### Item-level fit

```{r}
# (b) Item-level fit (S-X² or G² statistics)
itemfit_stats <- itemfit(mod2pl)
itemfit_stats  # significant misfit items should be reviewed
```

### Compare 1PL vs 2PL with likelihood ratio test

```{r}
# (c) Compare 1PL vs 2PL with likelihood ratio test
# Fit 1PL and 2PL models
mod1pl <- mirt(irt_mat, 1, itemtype = "Rasch")
mod2pl <- mirt(irt_mat, 1, itemtype = "2PL")

# Likelihood ratio test: does 2PL fit better than Rasch?
anova(mod1pl, mod2pl)

```

## Items Removal Plan 2 (Based on discrimination, difficulty and local dependence)

**Selection criteria a \> 0.64 (moderate discrimination) (Baker, 2001) ; -3 \< b \> +3**

K2 - a = 0.47

K3 - a = 0.39

K5 - a = 0.08 , b = -9.3762

K7 - a = 0.26

K8 - a = 0.20

K9 - a = 0.33

K10 - a = 0.30

K11 - a = 0.35

K24 - a = 16.9641 (?Overfitting)

K35 - a = 0.31

**Based on Local Dependence**

K4 : K4–K6 (LD 16.3; Q3 0.295)

K15 : K15–K16 (Q3 = 0.800; LD = 70.6)

K27 : K26–K27–K28–K29 (multiple LD \> 14; Q3 up to 0.556)

K34 : K34–K36–K37 (LD ≈ 12–13; Q3 ≈ 0.35–0.39)

### 2PL Model - Remove Items 2

```{r}
# Remove the items 
irt_removed_items2 <-c("K2", "K3", "K5", "K7", "K8", "K9", "K10", "K11","K35","K24","K4","K15","K27","K34")  

# Create new dataset with only included items
data5 <- data3 %>% dplyr::select(-any_of(irt_removed_items2))
```

### Descriptive Statistics

```{r}
descript(data5)
```

### Refit 2PL Model

```{r}
irt.data5 <- ltm(data5 ~ z1, IRT.param = TRUE)
```

### Item Parameter Estimates

```{r}
# Obtain difficulty and discrimination parameter estimates 
item_parms_refined2 <- coef(irt.data5)

# Tidy view: Item | a (Discrimination) | b (Difficulty)

pp <- coef(irt.data5)  # matrix with columns "Dffclt", "Dscrmn"

item_parms_refined_tbl2 <- data.frame(
  Item = rownames(pp),
  Difficulty = round(pp[,"Dffclt"], 3),
  Discrimination = round(pp[,"Dscrmn"], 3),
  row.names = NULL
)

item_parms_refined_tbl2

```

### Model Summary

```{r}
# Includes log-likelihood, AIC/BIC, SEs, and Wald z-values 
summary(irt.data5)
```

## Graphical Presentation

### Item Characteristic Curves (ICC)

```{r}
# ICC for All Items # Plot ICC for all items 
plot(irt.data5, type = "ICC", legend = TRUE)
```

```{r}
# ICC for Individual Items  

# Get total number of items 
ICC_items2 <- nrow(coef(irt.data5))  

# Plot ICC for each item 
for (i in 1:ICC_items2)  
plot(irt.data5, type = "ICC", legend = TRUE, items = i)
```

## Goodness-of-Fit Tests

### Item Fit Statistics

```{r}
item_fit2 <- item.fit(irt.data5) 
item_fit2
```

### Fit on the Two-Way Margins

```{r}
margins_output2 <- margins(irt.data5) 
margins_output2
```

### Person Fit Statistics

```{r}
person_fit2 <- person.fit(irt.data5) 
person_fit2
```

# Checking Assumptions

## Unidimensionality

```{r}
set.seed(2025) 
unidimTest(irt.data5) #Take A long time, insert # if want to skip and avoid long time}
```

### Checking Dominant Factor (Essential Unidimensionality)

```{r}
# Extract the response data from the fitted model 
irt_mat2 <- as.matrix(irt.data5$X)  
# Parallel analysis 
library(psych) 
fa.parallel(irt_mat2, fa="fa")  
# Eigenvalues 
ev2 <- eigen(cor(irt_mat2, use = "pairwise.complete.obs"))$values  
# First and second eigenvalues 
first_ev2 <- ev[1] 
second_ev2 <- ev[2]  
# Ratio 
dominance_ratio <- first_ev2 / second_ev2  
# Print first_ev second_ev dominance_ratio}
```

Parallel analysis suggested up to seven factors, as seven eigenvalues from the actual data exceeded those from randomly simulated data. However, the scree plot demonstrated a sharp drop between the first (9.02) and second (2.51) eigenvalues, yielding a ratio of 3.59. This indicates a single dominant factor underlying item responses, with additional weaker factors. Consistent with the concept of **essential unidimensionality** (Reckase, 1979; Hambleton, Swaminathan, & Rogers, 1991; Embretson & Reise, 2000), the scale was considered suitable for unidimensional IRT modeling despite the presence of minor secondary dimensions.

```{r}
class(irt.data5) 
str(irt.data5, max.level = 1)
```

## Local Independence

### Yen’s Q3 residual cYen’s Q3 residual correlationsorrelations

```{r}

library(mirt) 
library(mokken)  

# Extract the raw item response matrix from the ltm object 
irt_mat2 <- as.data.frame(irt.data5$X)   

# now it's a dataframe 
irt_mat2 <- as.matrix(irt_mat2)           

# convert to numeric matrix    

# 1. Fit a unidimensional 2PL model 

mod2pl2 <- mirt(irt_mat2, 1, itemtype = "2PL") 
mod1pl2 <- mirt(irt_mat2, 1, itemtype = "Rasch")  

# ========================================== 
```

```{r}
# 2. Assumption: Local Independence # ========================================== 

# (a) Yen’s Q3 residual correlations # 

Q3_resid2 <- residuals(mod2pl2, type = "Q3") 

# Assumption 2: Local Independence 

Q3_resid2 <- residuals(mod2pl2, type = "Q3")  
Q3_resid2   
```

From your matrix:

**K15–K16 = 0.800** (from your earlier results, still present at 0.697 max here → strongest dependence).

**K32–K33 = 0.580**

**K36–K37 = 0.406**

**K25–K23 ≈ 0.697 (based on earlier Q3 too)**

**K26–K28 ≈ 0.451**

**K29–K28 ≈ 0.448**

These values are far above the 0.20 threshold. They likely **share redundant variance** (overlapping wording or concept).

```{r}


# inspect residual correlations (Q3 > .20 may indicate local dependence)  

# Chen & Thissen’s LD χ² statistic 

LD_resid2 <- residuals(mod2pl2, type = "LD") 
LD_resid2  # values > 10 indicate local dependence}
```

1.  **K14–K16** Q3 = 0.375 (above cutoff \~0.20) LD = 21.5 (well above 10)

2.  **K19–K21** Q3 = –0.338 (negative correlation, not an issue) LD = \~1.0 (well below 10)

3.  **K23–K25** Q3 = 0.697 (very high, strongest in Q3) LD = 22.2 (extremely high)

4.  **K28–K29** Q3 = 0.451 (high) LD = 27.7 (critical)

5.  **K32–K33** Q3 = 0.580 (high) LD = 26.5 (critical)

6.  **K36–K37** Q3 = 0.406 (high) LD = 15.2 (well above 10)

### Monotonicity

```{r}
# ========================================== # 3. Assumption: Monotonicity # ==========================================  
# (a) Plot Item Characteristic Curves (ICCs) to visually check monotonicity 

plot(mod2pl2, type = "trace")   # S-shaped, increasing curves are expected  

# (b) Optional: Use Mokken scale analysis for monotonicity check  
# Run monotonicity check 
check.monotonicity(irt_mat2)  # flags items with non-monotonic patterns}
```

## Model Fitness

### Global fit statistics

```{r}
# ========================================== # 4. Assumption: Model Fit # ========================================== 
# (a) Global fit statistics (M2, RMSEA, SRMSR) 
M2(mod2pl2)   # RMSEA < 0.08 and SRMSR < 0.05 = good fit}
```

### Item-level fit

```{r}
# (b) Item-level fit (S-X² or G² statistics) 

itemfit_stats2 <- itemfit(mod2pl2) 
itemfit_stats  # significant misfit items should be reviewed}
```

### Compare 1PL vs 2PL with likelihood ratio test

```{r}
# (c) Compare 1PL vs 2PL with likelihood ratio test
# Fit 1PL and 2PL models
mod1pl2 <- mirt(irt_mat2, 1, itemtype = "Rasch")
mod2pl2 <- mirt(irt_mat2, 1, itemtype = "2PL")

# Likelihood ratio test: does 2PL fit better than Rasch?
anova(mod1pl2, mod2pl2)
```

# Fitting 2PL IRT Model with `mirt` Package

```{r}
mirt.data5 = mirt(data5, 1, itemtype = "2PL")
coef(mirt.data5, IRTpars = T, simplify = T)
```

```{r}
# Fit 2PL Model (mirt)

mirt.data5 <- mirt(data5, 1, itemtype = "2PL")
```

## Item Parameter Estimates (mirt)

```{r}
# Obtain difficulty (b), discrimination (a), guessing (g), upper bound (u)
mirt_parms2 <- coef(mirt.data5, IRTpars = TRUE, simplify = TRUE)
item_parms_refined_mirt2 <- mirt_parms2$items


# Tidy view: Item | Discrimination | Difficulty | Guessing Parameter | Upper Bound
item_parms_refined_tbl_mirt2 <- item_parms_refined_mirt2 |>
  as.data.frame() |>
  (\(d) {
    if (!"g" %in% names(d)) d$g <- NA_real_
    if (!"u" %in% names(d)) d$u <- NA_real_
    d
  })() |>
  transform(
    Item               = rownames(item_parms_refined_mirt2),
    Difficulty         = b,
    Discrimination     = a,
    `Guessing Parameter` = g,
    `Upper Bound`        = u
  ) |>
  (\(d) d[, c("Item", "Difficulty", "Discrimination", "Guessing Parameter", "Upper Bound")])() |>
  (\(d) within(d, {
    Difficulty          <- round(Difficulty, 3)
    Discrimination      <- round(Discrimination, 3)
    `Guessing Parameter`<- round(`Guessing Parameter`, 3)
    `Upper Bound`       <- round(`Upper Bound`, 3)
  }))()

item_parms_refined_tbl_mirt2
```

## Test Information

```{r}
areainfo(mirt.data5, c(-3,3))
```

## Graphical Presentation

### Item Trace Lines (Item Characteristic Curves)

```{r}
plot(mirt.data5, type = "trace")
```

### Item Information Curves

```{r}
plot(mirt.data5, type = "infotrace")
```

### Test Information Function

```{r}
plot(mirt.data5, type = "info")
```

### Test Information and Standard Error

```{r}
plot(mirt.data5, type = "infoSE")
```

### Expected Total Score

```{r}
plot(mirt.data5)
```

## Goodness-of-Fit Tests

### Overall Model Fit

```{r}
M2(mirt.data5)
```

### Item Fit Statistics

```{r}
itemfit(mirt.data5)
```

### Person Fit Statistics

```{r}
personfit(mirt.data5)
```

## Reliability Estimates

### Marginal Reliability

```{r}
marginal_rxx(mirt.data5)
```

### Empirical Reliability

```{r}
theta_se2 = fscores(mirt.data5, full.scores.SE = TRUE)
empirical_rxx(theta_se2)
```
