---
title: "IRT"
author: "firdaus"
format: docx
editor: visual
---

# Prepare Environment

## Load Libraries

```{r}
library(psych)        # For basic psychometrics and scale reliability analysis
library(foreign)      # For reading and writing data in foreign statistical formats
library(ltm)          # To fit 2PL IRT models and other latent trait models
library(irtoys)       # For IRT utilities
library(mirt)         # Modern IRT package for multi-item response theory
library(latticeExtra) # For enhanced plotting in lattice-based plots
library(tidyverse)    # For data manipulation, cleaning, and visualization
library(haven)        # For importing and exporting SPSS, Stata, and SAS files
library(writexl)      # For exporting data frames to Excel files
library(readxl)       # For reading data from Excel files
```

## Load Data

```{r}
data1=read_xlsx("IRT_knowledge_V1.xlsx") ##read data from Excel 
names(data1) # List down variables in the data set
dim(data1)  # Data set consists of 37 variables and 177 parents
```

### Recode Data

```{r}
# Define reverse-coded items
reverse_items <- c("K2", "K3", "K4", "K5", "K8", "K10", "K35")

# Recode
data2 <- data1 %>%
  mutate(across(
    -all_of(reverse_items), 
    ~ case_when(
      tolower(.) == "ya" ~ 1,
      tolower(.) == "tidak" ~ 0,
      tolower(.) == "tidak pasti" ~ 2,
      TRUE ~ NA_real_
    )
  )) %>%
  mutate(across(
    all_of(reverse_items),
     ~ case_when(
      tolower(.) == "ya" ~ 0,
      tolower(.) == "tidak" ~ 1,
      tolower(.) == "tidak pasti" ~ 2,
      TRUE ~ NA_real_
    )
  ))
```

```{r}
#Recode 1 = 1 (correct answer), 2 and 0 = 0 (incorrect answer)

data3 <- data2 %>%
  mutate(across(
    everything(),
    ~ case_when(
      . == 1 ~ 1,
      . %in% c(0, 2) ~ 0,
      TRUE ~ NA_real_
    )
  ))
```

# Descriptive Statistics

## Response Frequencies

```{r}
response.frequencies(data3)
```

### Descriptive Statistics

```{r}
descript(data3)
```

# Fitting 2PL IRT Model with `ltm` Package

## Fit 2PL Model (ltm)

```{r}
irt.data3 <- ltm(data3 ~ z1, IRT.param = TRUE)
```

## Item Parameter Estimates

```{r}
# Obtain difficulty and discrimination parameter estimates
item_parms <- coef(irt.data3)
```

```{r}
# Tidy view: Item | a (Discrimination) | b (Difficulty)

item_parms_tbl <- item_parms |>
  as.data.frame() |>
  transform(Item = rownames(item_parms),
            Difficulty = Dffclt,
            Discrimination = Dscrmn) |>
  (\(d) d[, c("Item", "Difficulty", "Discrimination")])() |>
  (\(d) within(d, { 
    Difficulty <- round(Difficulty, 3)
    Discrimination <- round(Discrimination, 3)
  }))()

item_parms_tbl
```

## Model Summary

```{r}
# Includes log-likelihood, AIC/BIC, SEs, and Wald z-values
summary(irt.data3)
```

## Items Removal Plan 1

**Selection criteria a \> 0.64 (moderate discrimination) (Baker, 2001) ; -3 \< b \> +3**

K2 - a = 0.47

K3 - a = 0.39

K5 - a = 0.08 , b = -9.3762

K7 - a = 0.26

K8 - a = 0.20

K9 - a = 0.33

K10 - a = 0.30

K11 - a = 0.35

K24 - a = 16.9641 (?Overfitting)

K35 - a = 0.31

### 2PL Model - Remove Items

```{r}
# Remove the items
irt_removed_items <- c("K2", "K3", "K5", "K7", "K8", "K9", "K10", "K11","K35","K24")

# Create new dataset with only included items
data4 <- data3 %>% dplyr::select(-any_of(irt_removed_items))
```

### Descriptive Statistics

```{r}
descript(data4)
```

### Refit 2PL Model

```{r}
irt.data4 <- ltm(data4 ~ z1, IRT.param = TRUE)
```

### Item Parameter Estimates

```{r}
# Obtain difficulty and discrimination parameter estimates
item_parms_refined <- coef(irt.data4)

# Tidy view: Item | a (Discrimination) | b (Difficulty)

item_parms_refined_tbl <- item_parms_refined |>
  as.data.frame() |>
  transform(Item = rownames(item_parms_refined),
            Difficulty = Dffclt,
            Discrimination = Dscrmn) |>
  (\(d) d[, c("Item", "Difficulty", "Discrimination")])() |>
  (\(d) within(d, { 
    Difficulty <- round(Difficulty, 3)
    Discrimination <- round(Discrimination, 3)
  }))()

item_parms_refined_tbl
```

### Model Summary

```{r}
# Includes log-likelihood, AIC/BIC, SEs, and Wald z-values
summary(irt.data4)
```

## Graphical Presentation

### Item Characteristic Curves (ICC)

```{r}
# ICC for All Items
# Plot ICC for all items
plot(irt.data4, type = "ICC", legend = TRUE)
```

```{r}
# ICC for Individual Items

# Get total number of items
ICC_items <- nrow(coef(irt.data4))

# Plot ICC for each item
for (i in 1:ICC_items) {
  plot(irt.data4, type = "ICC", legend = TRUE, items = i)
}
```

## Goodness-of-Fit Tests

### Item Fit Statistics

```{r}
item_fit <- item.fit(irt.data4)
item_fit
```

### Fit on the Two-Way Margins

```{r}
margins_output <- margins(irt.data4)
margins_output
```

### Person Fit Statistics

```{r}
person_fit <- person.fit(irt.data4)
person_fit
```

# Checking Assumptions

## Unidimensionality

```{r}
set.seed(2025)
#unidimTest(irt.data4) #Take A long time, insert # if want to skip and avoid long time
```

### Checking Dominant Factor (Essential Unidimensionality)

```{r}
# Extract the response data from the fitted model
irt_mat <- as.matrix(irt.data4$X)

# Parallel analysis
library(psych)
fa.parallel(irt_mat, fa="fa")

# Eigenvalues
ev <- eigen(cor(irt_mat, use = "pairwise.complete.obs"))$values

# First and second eigenvalues
first_ev <- ev[1]
second_ev <- ev[2]

# Ratio
dominance_ratio <- first_ev / second_ev

# Print
first_ev
second_ev
dominance_ratio

```

Parallel analysis suggested up to seven factors, as seven eigenvalues from the actual data exceeded those from randomly simulated data. However, the scree plot demonstrated a sharp drop between the first (9.02) and second (2.51) eigenvalues, yielding a ratio of 3.59. This indicates a single dominant factor underlying item responses, with additional weaker factors. Consistent with the concept of **essential unidimensionality** (Reckase, 1979; Hambleton, Swaminathan, & Rogers, 1991; Embretson & Reise, 2000), the scale was considered suitable for unidimensional IRT modeling despite the presence of minor secondary dimensions.

```{r}
class(irt.data4)
str(irt.data4, max.level = 1)

```

## Local Independence

### Yen’s Q3 residual cYen’s Q3 residual correlationsorrelations

```{r}
# ==========================================
# Load required package
# ==========================================
library(mirt)
library(mokken)

# Extract the raw item response matrix from the ltm object
irt_mat <- as.data.frame(irt.data4$X)   # now it's a dataframe
irt_mat <- as.matrix(irt_mat)           # convert to numeric matrix



# ==========================================
# 1. Fit a unidimensional 2PL model
# ==========================================

mod2pl <- mirt(irt_mat, 1, itemtype = "2PL")
mod1pl <- mirt(irt_mat, 1, itemtype = "Rasch")

# ==========================================
# 2. Assumption: Local Independence
# ==========================================
# (a) Yen’s Q3 residual correlations
# Q3_resid <- resid(mod2pl, type = "Q3")
# Assumption 2: Local Independence
Q3_resid <- residuals(mod2pl, type = "Q3")

Q3_resid   # inspect residual correlations (Q3 > .20 may indicate local dependence)

# Chen & Thissen’s LD χ² statistic
LD_resid <- residuals(mod2pl, type = "LD")
LD_resid  # values > 10 indicate local dependence
```

## Monotonicity

```{r}
# ==========================================
# 3. Assumption: Monotonicity
# ==========================================

# (a) Plot Item Characteristic Curves (ICCs) to visually check monotonicity
plot(mod2pl, type = "trace")   # S-shaped, increasing curves are expected

# (b) Optional: Use Mokken scale analysis for monotonicity check

# Run monotonicity check
check.monotonicity(irt_mat)  # flags items with non-monotonic patterns
```

## Model Fitness

### Global fit statistics

```{r}
# ==========================================
# 4. Assumption: Model Fit
# ==========================================
# (a) Global fit statistics (M2, RMSEA, SRMSR)
M2(mod2pl)   # RMSEA < 0.08 and SRMSR < 0.05 = good fit
```

### Item-level fit

```{r}
# (b) Item-level fit (S-X² or G² statistics)
itemfit_stats <- itemfit(mod2pl)
itemfit_stats  # significant misfit items should be reviewed
```

### Compare 1PL vs 2PL with likelihood ratio test

```{r}
# (c) Compare 1PL vs 2PL with likelihood ratio test
# Fit 1PL and 2PL models
mod1pl <- mirt(irt_mat, 1, itemtype = "Rasch")
mod2pl <- mirt(irt_mat, 1, itemtype = "2PL")

# Likelihood ratio test: does 2PL fit better than Rasch?
anova(mod1pl, mod2pl)

```

# Fitting 2PL IRT Model with `mirt` Package

```{r}
mirt.data4 = mirt(data4, 1, itemtype = "2PL")
coef(mirt.data4, IRTpars = T, simplify = T)
```

```{r}
# Fit 2PL Model (mirt)

mirt.data4 <- mirt(data4, 1, itemtype = "2PL")
```

## Item Parameter Estimates (mirt)

```{r}
# Obtain difficulty (b), discrimination (a), guessing (g), upper bound (u)
mirt_parms <- coef(mirt.data4, IRTpars = TRUE, simplify = TRUE)
item_parms_refined_mirt <- mirt_parms$items


# Tidy view: Item | Discrimination | Difficulty | Guessing Parameter | Upper Bound
item_parms_refined_tbl_mirt <- item_parms_refined_mirt |>
  as.data.frame() |>
  (\(d) {
    if (!"g" %in% names(d)) d$g <- NA_real_
    if (!"u" %in% names(d)) d$u <- NA_real_
    d
  })() |>
  transform(
    Item               = rownames(item_parms_refined_mirt),
    Difficulty         = b,
    Discrimination     = a,
    `Guessing Parameter` = g,
    `Upper Bound`        = u
  ) |>
  (\(d) d[, c("Item", "Difficulty", "Discrimination", "Guessing Parameter", "Upper Bound")])() |>
  (\(d) within(d, {
    Difficulty          <- round(Difficulty, 3)
    Discrimination      <- round(Discrimination, 3)
    `Guessing Parameter`<- round(`Guessing Parameter`, 3)
    `Upper Bound`       <- round(`Upper Bound`, 3)
  }))()

item_parms_refined_tbl_mirt
```

## Test Information

```{r}
areainfo(mirt.data4, c(-3,3))
```

## Graphical Presentation

### Item Trace Lines (Item Characteristic Curves)

```{r}
plot(mirt.data4, type = "trace")
```

### Item Information Curves

```{r}
plot(mirt.data4, type = "infotrace")
```

### Test Information Function

```{r}
plot(mirt.data4, type = "info")
```

### Test Information and Standard Error

```{r}
plot(mirt.data4, type = "infoSE")
```

### Expected Total Score

```{r}
plot(mirt.data4)
```

## Goodness-of-Fit Tests

### Overall Model Fit

```{r}
M2(mirt.data4)
```

### Item Fit Statistics

```{r}
itemfit(mirt.data4)
```

### Person Fit Statistics

```{r}
personfit(mirt.data4)
```

## Reliability Estimates

### Marginal Reliability

```{r}
marginal_rxx(mirt.data4)
```

### Empirical Reliability

```{r}
theta_se = fscores(mirt.data4, full.scores.SE = TRUE)
empirical_rxx(theta_se)
```
